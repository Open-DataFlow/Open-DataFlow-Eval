

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Video Data Evaluation Metrics &mdash; Open-DataFlow-Eval 0.1 文档</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=7c91f8fd"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/translations.js?v=beaddf03"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="视频数据评估指标" href="video_metrics.zh-CN.html" />
    <link rel="prev" title="文本数据评估指标" href="text_metrics.zh-CN.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Open-DataFlow-Eval
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">Open-DataFlow-Eval:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started/index.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Metrics</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="image_metrics.html">Image Data Evaluation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="image_metrics.zh-CN.html">图像数据评估指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_metrics.html">Text Data Evaluation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="text_metrics.zh-CN.html">文本数据评估指标</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Video Data Evaluation Metrics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pure-video-evaluation-metrics">Pure Video Evaluation Metrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#metric-categories">Metric Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="#metric-descriptions">Metric Descriptions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reference-values">Reference Values</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#video-text-evaluation-metrics">Video-Text Evaluation Metrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Reference Values</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="video_metrics.zh-CN.html">视频数据评估指标</a></li>
<li class="toctree-l2"><a class="reference internal" href="synth_metrics.html">Synth</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Open-DataFlow-Eval</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Metrics</a></li>
      <li class="breadcrumb-item active">Video Data Evaluation Metrics</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/src/metrics/video_metrics.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="video-data-evaluation-metrics">
<h1>Video Data Evaluation Metrics<a class="headerlink" href="#video-data-evaluation-metrics" title="Link to this heading"></a></h1>
<section id="pure-video-evaluation-metrics">
<h2>Pure Video Evaluation Metrics<a class="headerlink" href="#pure-video-evaluation-metrics" title="Link to this heading"></a></h2>
<section id="metric-categories">
<h3>Metric Categories<a class="headerlink" href="#metric-categories" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Category Description</p></th>
<th class="head"><p>Metric List</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Based on Video Statistics</p></td>
<td><p>Motion Score</p></td>
</tr>
<tr class="row-odd"><td><p>Based on Pre-trained Models</p></td>
<td><p>FastVQAScorer, FasterVQAScorer, DOVERScorer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="metric-descriptions">
<h3>Metric Descriptions<a class="headerlink" href="#metric-descriptions" title="Link to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Evaluation Metric</p></th>
<th class="head"><p>Dimension</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Value Range</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>VideoMotionScorer</p></td>
<td><p>Motion Score</p></td>
<td><p>Statistical</p></td>
<td><p>Calculates the magnitude of optical flow vectors between frames as the score</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://arxiv.org/abs/2207.02595v1">FastVQAScorer</a></p></td>
<td><p>Pre-trained Model Scoring</p></td>
<td><p>Model</p></td>
<td><p>Scorer based on Video Swin Transformer, incorporating the Fragment Sampling module, which improves accuracy and speed</p></td>
<td><p>[0,1]</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://arxiv.org/abs/2210.05357">FasterVQAScorer</a></p></td>
<td><p>Pre-trained Model Scoring</p></td>
<td><p>Model</p></td>
<td><p>An optimized version of FastVQAScorer, with improvements to the Fragment Sampling module, achieving significant speed enhancements</p></td>
<td><p>[0,1]</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://arxiv.org/abs/2211.04894">DOVERScorer</a></p></td>
<td><p>Pre-trained Model Scoring</p></td>
<td><p>Model</p></td>
<td><p>Based on FastVQAScorer, it provides scores from both technical and aesthetic perspectives</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="reference-values">
<h3>Reference Values<a class="headerlink" href="#reference-values" title="Link to this heading"></a></h3>
<p>To better provide data quality references, we evaluated the KoNViD-1k dataset using the above metrics, and the distribution of the evaluation values is as follows:</p>
<table class="tg"><thead>
  <tr>
    <th class="tg-0pky">Metric</th>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Mean</th>
    <th class="tg-0pky">Variance</th>
    <th class="tg-0pky">Max</th>
    <th class="tg-0pky">Min</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-0pky">Motion Score</td>
    <td class="tg-0pky"></td>
    <td class="tg-0pky">Calculates the magnitude of the optical flow vectors between video frames as the score. The stronger the motion in the video, the greater the frame-to-frame changes, and the higher the score</td>
    <td class="tg-0pky">6.2745</td>
    <td class="tg-0pky">19.28</td>
    <td class="tg-0pky">25.23</td>
    <td class="tg-0pky">0.001623</td>
  </tr>
  <tr>
    <td class="tg-0pky" >FastVQA</td>
    <td class="tg-0pky"></td>
    <td class="tg-0pky">The score obtained using the FastVQAScorer module. The better the video quality, the higher the score</td>
    <td class="tg-0pky">0.4987</td>
    <td class="tg-0pky">0.04554</td>
    <td class="tg-0pky">0.9258</td>
    <td class="tg-0pky">0.007619</td>
  </tr>
  <tr>
    <td class="tg-0pky">FasterVQA</td>
    <td class="tg-0pky"></td>
    <td class="tg-0pky">The score obtained using the FasterVQAScorer module. The better the video quality, the higher the score</td>
    <td class="tg-0pky">0.5134</td>
    <td class="tg-0pky">0.04558</td>
    <td class="tg-0pky">0.9066</td>
    <td class="tg-0pky">0.03686</td>
  </tr>
  <tr>
    <td class="tg-0pky" rowspan="2">DOVER</td>
    <td class="tg-0pky">technical</td>
    <td class="tg-0pky">One of the scores obtained using the DOVERScorer module, the better the technical quality of the video, the higher the score</td>
    <td class="tg-0pky">-0.1107</td>
    <td class="tg-0pky">0.001755</td>
    <td class="tg-0pky">-0.006550</td>
    <td class="tg-0pky">-0.3175</td>
  </tr>
  <tr>
    <td class="tg-0pky">aesthetic</td>
    <td class="tg-0pky">One of the scores obtained using the DOVERScorer module, the better the aesthetic quality of the video, the higher the score</td>
    <td class="tg-0pky">-0.008419</td>
    <td class="tg-0pky">0.004569</td>
    <td class="tg-0pky">0.1869</td>
    <td class="tg-0pky">-0.2629</td>
  </tr>
</tbody></table>
</section>
</section>
<section id="video-text-evaluation-metrics">
<h2>Video-Text Evaluation Metrics<a class="headerlink" href="#video-text-evaluation-metrics" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Category Description</p></th>
<th class="head"><p>Metric List</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Based on Pre-trained Vision-Language Models</p></td>
<td><p>EMScore, PAC-S</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Evaluation Metric</p></th>
<th class="head"><p>Dimension</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Value Range</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://arxiv.org/abs/2111.08919">EMScorer</a></p></td>
<td><p>Video-Text Similarity Scoring</p></td>
<td><p>Model</p></td>
<td><p>A video-text scorer based on CLIP, supporting both with-reference and no-reference scoring.</p></td>
<td><p>[0,1]</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://arxiv.org/abs/2303.12112">PACScorer</a></p></td>
<td><p>Video-Text Similarity Scoring</p></td>
<td><p>Model</p></td>
<td><p>A video-text scorer based on CLIP, with tuned CLIP Encoder on top of EMScore</p></td>
<td><p>[0,1]</p></td>
</tr>
</tbody>
</table>
<section id="id1">
<h3>Reference Values<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p>To provide better data quality reference, we evaluated the VATEX dataset (<a class="reference external" href="https://huggingface.co/datasets/lmms-lab/VATEX">link</a>) using the above metrics, and the distribution of the metric values is as follows:</p>
<table class="tg"><thead>
  <tr>
    <th class="tg-0pky">Metric</th>
    <th class="tg-0pky">Name</th>
    <th class="tg-0pky">Mean</th>
    <th class="tg-0pky">Variance</th>
    <th class="tg-0pky">Max</th>
    <th class="tg-0pky">Min</th>
  </tr></thead>
<tbody>
  <tr>
    <td class="tg-0pky" rowspan="3">EMScorer</td>
    <td class="tg-0pky">figr_F</td>
    <td class="tg-0pky">The score obtained using the EMScorer module. The higher the similarity between the video and text at a fine-grained level, the higher the score	</td>
    <td class="tg-0pky">0.2712</td>
    <td class="tg-0pky">0.0003667</td>
    <td class="tg-0pky">0.3461</td>
    <td class="tg-0pky">0.1987</td>
  </tr>
  <tr>
    <td class="tg-0pky">cogr</td>
    <td class="tg-0pky">The score obtained using the EMScorer module. The higher the similarity between the video and text at a coarse-grained level, the higher the score	</td>
    <td class="tg-0pky">0.3106</td>
    <td class="tg-0pky">0.0009184</td>
    <td class="tg-0pky">0.4144</td>
    <td class="tg-0pky">0.18</td>
  </tr>
    <tr>
    <td class="tg-0pky">full_F</td>
    <td class="tg-0pky">The score obtained using the EMScorer module, which is the arithmetic mean of the above two scores</td>
    <td class="tg-0pky">0.2909</td>
    <td class="tg-0pky">0.0005776</td>
    <td class="tg-0pky">0.3712</td>
    <td class="tg-0pky">0.3807</td>
  </tr>
  <tr>
    <td class="tg-0pky" rowspan="3">PACScorer</td>
    <td class="tg-0pky">figr_F</td>
    <td class="tg-0pky">The score obtained using the PACScorer module. The higher the similarity between the video and text at a fine-grained level, the higher the score</td>
    <td class="tg-0pky">0.36553</td>
    <td class="tg-0pky">0.0004902</td>
    <td class="tg-0pky">0.4456</td>
    <td class="tg-0pky">0.2778</td>
  </tr>
  <tr>
    <td class="tg-0pky">cogr</td>
    <td class="tg-0pky">The score obtained using the PACScorer module. The higher the similarity between the video and text at a coarse-grained level, the higher the score	</td>
    <td class="tg-0pky">0.4160</td>
    <td class="tg-0pky">0.001021</td>
    <td class="tg-0pky">0.5222</td>
    <td class="tg-0pky">0.2510</td>
  </tr>
    <tr>
    <td class="tg-0pky">full_F</td>
    <td class="tg-0pky">The score obtained using the PACScorer module, which is the arithmetic mean of the above two scores	</td>
    <td class="tg-0pky">0.3908</td>
    <td class="tg-0pky">0.0006854</td>
    <td class="tg-0pky">0.4761</td>
    <td class="tg-0pky">0.2681</td>
  </tr></section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="text_metrics.zh-CN.html" class="btn btn-neutral float-left" title="文本数据评估指标" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="video_metrics.zh-CN.html" class="btn btn-neutral float-right" title="视频数据评估指标" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024, Open-DataFlow。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>